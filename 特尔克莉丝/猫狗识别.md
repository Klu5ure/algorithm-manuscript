txt.py 获取猫狗图片地址并分类
data.py 处理猫狗图片，方便神经网络读取
main.py 训练网络，生成模型
predict.py 调用模型，接受图片进行预测

先运行txt.py，然后运行main.py生成模型，最后在predict.py设置好模型和图片的路径进行检测

# vggmast

## txt.py

在train文件夹中，有cat和dog两个文件夹，里面包含了猫狗的图片（例如cat.1.jpg、dog.434.jpg）。运行txt.py，会生成一个cls_train.txt文件，包含猫狗图片的类别和路径，如下所示

```txt
0;D:\errorhassei\project\vggmast/train\cat\cat.1.jpg
0;D:\errorhassei\project\vggmast/train\cat\cat.10.jpg
0;D:\errorhassei\project\vggmast/train\cat\cat.100.jpg
0;D:\errorhassei\project\vggmast/train\cat\cat.101.jpg
0;D:\errorhassei\project\vggmast/train\cat\cat.102.jpg
0;D:\errorhassei\project\vggmast/train\cat\cat.103.jpg

1;D:\errorhassei\project\vggmast/train\dog\dog.434.jpg
1;D:\errorhassei\project\vggmast/train\dog\dog.435.jpg
1;D:\errorhassei\project\vggmast/train\dog\dog.436.jpg
1;D:\errorhassei\project\vggmast/train\dog\dog.437.jpg
1;D:\errorhassei\project\vggmast/train\dog\dog.438.jpg
1;D:\errorhassei\project\vggmast/train\dog\dog.439.jpg
1;D:\errorhassei\project\vggmast/train\dog\dog.44.jpg
```

代码和注释如下

```python
# 导入操作系统模块和获取当前工作目录的函数
import os
from os import getcwd

# 定义两个类别标签，'cat' 和 'dog'
classes=['cat','dog']

# 定义数据集的集合，这里只有 'train' 一个训练集
sets=['train']

# 程序的主入口
if __name__=='__main__':
    # 获取当前工作目录的路径
    wd=getcwd()
    
    # 遍历数据集集合
    for se in sets:
        # 打开一个用于写入的文件，文件名根据数据集集合中的元素动态生成
        list_file=open('cls_'+ se +'.txt','w')

        # 设置数据集的路径
        datasets_path=se
        
        # 获取数据集路径下的所有文件和文件夹的名称
        types_name=os.listdir(datasets_path)
        
        # 遍历所有文件和文件夹的名称
        for type_name in types_name:
            # 如果当前名称不在类别标签中，则跳过
            if type_name not in classes:
                continue
            
            # 获取类别标签的索引，用于后续的分类标识
            cls_id=classes.index(type_name)
            
            # 构建每个类别的图片存储路径
            photos_path=os.path.join(datasets_path,type_name)
            
            # 获取类别路径下的所有图片文件名称
            photos_name=os.listdir(photos_path)
            
            # 遍历所有图片文件名称
            for photo_name in photos_name:
                # 分离文件名和扩展名
                _,postfix=os.path.splitext(photo_name)
                
                # 如果文件扩展名不是图片格式，则跳过
                if postfix not in['.jpg','.png','.jpeg']:
                    continue
                
                # 写入类别标识和图片的完整路径到文件
                list_file.write(str(cls_id)+';'+'%s/%s'%(wd, os.path.join(photos_path,photo_name)))
                
                # 每个图片路径后添加换行符，便于区分不同的图片
                list_file.write('\n')
        
        # 关闭文件，完成写入操作
        list_file.close()
```

## data.py

由于图片的格式、大小尺寸等可能都不一致，所以需要先经过处理才能放到神经网络里进行训练。

这段代码是一个用于图像处理的数据生成器，主要用于机器学习中的数据增强。它通过随机变换图像（如缩放、裁剪、旋转、颜色变换等）来增加数据集的多样性，从而提高模型的泛化能力。下面是对代码中每个函数的详细注释：

```python
# 导入所需的库
import cv2
import numpy as np
import torch.utils.data as data
from PIL import Image

# 预处理函数，将图像像素值标准化到[-1, 1]区间
def preprocess_input(x):
    # 将像素值缩放到[-1, 1]区间
    x /= 127.5
    x -= 1.
    return x

# 确保图像是RGB格式的函数
def cvtColor(image):
    # 如果图像已经是RGB格式，直接返回
    if len(np.shape(image)) == 3 and np.shape(image)[-2] == 3:
        return image
    else:
        # 将图像转换为RGB格式
        image = image.convert('RGB')
        return image

# 自定义的数据生成器类，继承自torch.utils.data.Dataset
class DataGenerator(data.Dataset):
    # 初始化函数
    def __init__(self, annotation_lines, input_shape, random=True):
        self.annotation_lines = annotation_lines  # 存储图像路径和标签的列表
        self.input_shape = input_shape  # 输入图像的目标尺寸
        self.random = random  # 是否应用随机变换

    # 返回数据集的大小
    def __len__(self):
        return len(self.annotation_lines)

    # 根据索引获取数据集中的图像和标签
    def __getitem__(self, index):
        # 解析图像路径和标签
        annotation_path = self.annotation_lines[index].split(';')[1].split()[0]
        image = Image.open(annotation_path)  # 打开图像
        # 应用随机变换
        image = self.get_random_data(image, self.input_shape, random=self.random)
        # 转换图像为numpy数组，并进行预处理
        image = np.transpose(preprocess_input(np.array(image).astype(np.float32)), [2, 0, 1])
        # 获取标签
        y = int(self.annotation_lines[index].split(';')[0])
        return image, y

    # 生成随机数的辅助函数
    def rand(self, a=0, b=1):
        return np.random.rand() * (b - a) + a

    # 应用随机变换的函数
    def get_random_data(self, image, inpt_shape, jitter=.3, hue=.1, sat=1.5, val=1.5, random=True):
        # 确保图像是RGB格式
        image = cvtColor(image)
        # 获取图像的宽度和高度
        iw, ih = image.size
        h, w = inpt_shape
        # 如果不应用随机变换，直接缩放并居中裁剪图像
        if not random:
            scale = min(w / iw, h / ih)
            nw = int(iw * scale)
            nh = int(ih * scale)
            dx = (w - nw) // 2
            dy = (h - nh) // 2
            image = image.resize((nw, nh), Image.BICUBIC)
            new_image = Image.new('RGB', (w, h), (128, 128, 128))
            new_image.paste(image, (dx, dy))
            image_data = np.array(new_image, np.float32)
            return image_data
        else:
            # 随机变换参数
            new_ar = w / h * self.rand(1 - jitter, 1 + jitter) / self.rand(1 - jitter, 1 + jitter)
            scale = self.rand(.75, 1.25)
            if new_ar < 1:
                nh = int(scale * h)
                nw = int(nh * new_ar)
            else:
                nw = int(scale * w)
                nh = int(nw / new_ar)
            image = image.resize((nw, nh), Image.BICUBIC)
            # 随机裁剪
            dx = int(self.rand(0, w - nw))
            dy = int(self.rand(0, h - nh))
            new_image = Image.new('RGB', (w, h), (128, 128, 128))
            new_image.paste(image, (dx, dy))
            image = new_image
            # 随机翻转
            flip = self.rand() < .5
            if flip:
                image = image.transpose(Image.FLIP_LEFT_RIGHT)
            # 随机旋转
            rotate = self.rand() < .5
            if rotate:
                angle = np.random.randint(-15, 15)
                a, b = w / 2, h / 2
                M = cv2.getRotationMatrix2D((a, b), angle, 1)
                image = cv2.warpAffine(np.array(image), M, (w, h), borderValue=[128, 128, 128])
            # 随机颜色变换
            hue = self.rand(-hue, hue)
            sat = self.rand(1, sat) if self.rand() < .5 else 1 / self.rand(1, sat)
            val = self.rand(1, val) if self.rand() < .5 else 1 / self.rand(1, val)
            # 转换颜色空间
            x = cv2.cvtColor(np.array(image, np.float32) / 255, cv2.COLOR_RGB2HSV)
            x[..., 1] *= sat  # 饱和度变换
            x[..., 2] *= val  # 亮度变换
            x[x[:, :, 0] > 360, 0] = 360
            x[:, :, 1:][x[:, :, 1:] > 1] = 1
            x[x < 0] = 0
            image_data = cv2.cvtColor(x, cv2.COLOR_HSV2RGB) * 255
            return image_data
```

## net.py

一个VGG16模型，这是一个在计算机视觉领域广泛使用的卷积神经网络架构。VGG16由16个权重层组成，主要用于图像识别和分类任务。结构如下

![1714009082631](Z:\技术学习资料\python人工智能\lzj\assets\1714009082631.png)

下面是对代码中每个部分的详细注释：

```python
import torch
import torch.nn as nn
from torch.hub import load_state_dict_from_url

# 预训练模型的权重下载网址
model_urls = {
    "vgg16": "https://download.pytorch.org/models/vgg16-397923af.pth", 
}

# 定义VGG模型类
class VGG(nn.Module):
    def __init__(self, features, num_classes = 1000, init_weights=True, dropout=0.5):
        super(VGG, self).__init__()
        # features是VGG网络中的特征提取层
        self.features = features
        # AdaptiveAvgPool2d用于在不同大小的输入图像上进行特征提取
        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))
        # classifier是VGG网络中的全连接层
        self.classifier = nn.Sequential(
            nn.Linear(512 * 7 * 7, 4096),
            nn.ReLU(True),
            nn.Dropout(p=dropout),
            nn.Linear(4096, 4096),
            nn.ReLU(True),
            nn.Dropout(p=dropout),
            nn.Linear(4096, num_classes),  # 最后一层全连接层的输出维度等于分类的类别数
        )
        # 初始化权重
        if init_weights:
            for m in self.modules():
                if isinstance(m, nn.Conv2d):
                    nn.init.kaiming_normal_(m.weight, mode="fan_out", nonlinearity="relu")
                    if m.bias is not None:
                        nn.init.constant_(m.bias, 0)
                elif isinstance(m, nn.BatchNorm2d):
                    nn.init.constant_(m.weight, 1)
                    nn.init.constant_(m.bias, 0)
                elif isinstance(m, nn.Linear):
                    nn.init.normal_(m.weight, 0, 0.01)
                    nn.init.constant_(m.bias, 0)

    # 定义前向传播过程
    def forward(self, x):
        x = self.features(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)  # 将特征图展平为一维
        x = self.classifier(x)
        return x

# make_layers函数根据给定的配置生成VGG的特征提取层
def make_layers(cfg, batch_norm=False):
    layers = []
    in_channels = 3  # 输入图像的通道数
    for v in cfg:
        if v == "M":
            # 最大池化层，用于下采样
            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]
        else:
            # 卷积层，v表示输出通道数
            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)
            if batch_norm:
                # 如果使用批量归一化
                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]
            else:
                layers += [conv2d, nn.ReLU(inplace=True)]
            in_channels = v
    return nn.Sequential(*layers)

# VGG网络的配置
cfgs = {
    "D": [64, 64, "M", 128, 128, "M", 256, 256, 256, "M", 512, 512, 512, "M", 512, 512, 512, "M"],
}

# vgg16函数用于创建VGG16模型实例
def vgg16(pretrained=False, progress=True, num_classes=1000):
    model = VGG(make_layers(cfgs['D']))
    if pretrained:
        try:
            # 尝试从给定的网址下载预训练权重
            state_dict = load_state_dict_from_url(model_urls['vgg16'], model_dir='./model', progress=progress)
            model.load_state_dict(state_dict)
        except Exception as e:
            # 如果下载失败，打印错误信息
            print(f"Failed to download the pre-trained weights. Error: {e}")
    if num_classes != 1000:
        # 如果类别数不是1000，修改最后一层的输出维度
        model.classifier = nn.Sequential(
            nn.Linear(512 * 7 * 7, 4096),
            nn.ReLU(True),
            nn.Dropout(p=0.5),
            nn.Linear(4096, 4096),
            nn.ReLU(True),
            nn.Dropout(p=0.5),
            nn.Linear(4096, num_classes),
        )
    return model

# 主程序
if __name__ == '__main__':
    # 创建一个输入张量，大小为1x3x224x224，用于模拟一个图像
    in_data = torch.ones(1, 3, 224, 224)
    # 创建VGG16模型实例，不下载预训练权重，输出类别数为2
    net = vgg16(pretrained=False, progress=True, num_classes=2)
    # 将输入数据传递给模型，获取输出
    out = net(in_data)
    # 打印输出结果
    print(out)
```

这段代码首先定义了VGG16模型的结构，包括卷积层、池化层和全连接层。然后通过`make_layers`函数根据VGG的配置生成网络层。`vgg16`函数用于创建VGG16模型实例，并提供了下载预训练权重和修改输出类别数的选项。最后，在主程序中，创建了一个模拟输入张量，通过模型获取输出，并打印了结果。需要注意的是，由于网络原因，预训练权重的下载可能失败，这时应该检查网络连接或尝试手动下载权重文件。

## main.py

一个使用PyTorch框架实现的深度学习训练流程，主要用于图像分类任务。代码中使用了VGG16网络架构，并在自建的数据集上进行训练和测试。下面是对代码中每个部分的详细注释：

```python
import torch
import torch.nn as nn
from net import vgg16  # 导入自定义的VGG16网络结构
from torch.utils.data import DataLoader  # 导入数据加载器，用于批量读取数据
from data import *  # 导入数据处理相关的函数和类

# 定义数据集
annotation_path = 'cls_train.txt'  # 训练集的注释文件路径
with open(annotation_path, 'r') as f:
    lines = f.readlines()  # 读取注释文件中的数据
np.random.seed(10101)  # 设置随机数种子，确保结果可复现
np.random.shuffle(lines)  # 将数据随机打乱，避免过拟合
np.random.seed(None)  # 重置随机数种子
num_val = int(len(lines) * 0.2)  # 划分20%的数据作为验证集
num_train = len(lines) - num_val  # 剩余数据作为训练集
input_shape = [224, 224]  # 定义输入图像的大小

# 创建数据生成器，用于加载和预处理图像数据
train_data = DataGenerator(lines[:num_train], input_shape, True)  # 训练集
val_data = DataGenerator(lines[num_train:], input_shape, False)  # 验证集
val_len = len(val_data)  # 验证集的长度

# 创建数据加载器，用于批量读取数据
gen_train = DataLoader(train_data, batch_size=4)  # 训练集数据加载器
gen_test = DataLoader(val_data, batch_size=4)  # 验证集数据加载器

# 构建网络
device = torch.device('cuda' if torch.cuda.is_available() else "cpu")  # 选择使用CPU或GPU
net = vgg16(True, progress=True, num_classes=2)  # 创建VGG16网络实例，加载预训练权重，设置类别数为2
net.to(device)  # 将网络移动到指定的设备上

# 选择优化器和学习率调整方法
lr = 0.0001  # 定义学习率
optim = torch.optim.Adam(net.parameters(), lr=lr)  # 创建Adam优化器
scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=1)  # 创建学习率调整器，步长为1

# 训练网络
epochs = 20  # 定义训练的轮数
for epoch in range(epochs):
    total_train = 0  # 定义总损失
    for data in gen_train:  # 遍历训练集数据
        img, label = data
        with torch.no_grad():  # 禁用梯度计算
            img = img.to(device)
            label = label.to(device)
        optim.zero_grad()  # 清空梯度
        output = net(img)  # 网络前向传播
        train_loss = nn.CrossEntropyLoss()(output, label).to(device)  # 计算交叉熵损失
        train_loss.backward()  # 反向传播
        optim.step()  # 更新网络参数
        total_train += train_loss  # 累加损失

    scheduler.step()  # 更新学习率

    total_test = 0  # 定义总损失
    total_accuracy = 0  # 定义总精度
    for data in gen_test:  # 遍历验证集数据
        img, label = data
        with torch.no_grad():  # 禁用梯度计算
            img = img.to(device)
            label = label.to(device)
        out = net(img)  # 网络前向传播
        test_loss = nn.CrossEntropyLoss()(out, label).to(device)  # 计算交叉熵损失
        total_test += test_loss  # 累加损失
        accuracy = ((out.argmax(1) == label).sum()).clone().detach().cpu().numpy()  # 计算精度
        total_accuracy += accuracy

    # 打印训练集和验证集的损失及精度
    print("训练集上的损失：{}".format(total_train))
    print("测试集上的损失：{}".format(total_test))
    print("测试集上的精度：{:.1%}".format(total_accuracy / val_len))  # 打印精度百分比

    # 保存模型
    torch.save(net.state_dict(), "DogandCat{}.pth".format(epoch + 1))
    print("模型已保存")
```

这段代码展示了一个完整的训练流程，包括数据准备、模型构建、训练、验证和保存模型。通过这个流程，可以训练出一个能够对图像进行分类的深度学习模型。代码中使用了数据增强、交叉熵损失函数和Adam优化器等深度学习中常用的技术和方法。此外，还使用了学习率调度器来调整学习率，以提高模型的收敛速度和性能。最后，每轮训练结束后，模型的权重被保存下来，以便于后续的评估和使用。

## predict.py

一个图像分类的预测脚本，使用PyTorch框架和VGG16模型来对单个图像进行分类。代码的主要步骤包括图像预处理、模型加载、前向传播和结果展示。下面是对代码中每个部分的详细注释：

```python
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt
import torch
import torch.nn.functional as F
from net import vgg16

# 设置待检测的图像路径
test_pth = r'E:\before\O3.jpg'

# 使用PIL库打开图像
test = Image.open(test_pth)

# 图片预处理
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # 将图像调整为224x224大小
    transforms.ToTensor()  # 将PIL图像转换为Tensor
])
# 应用预处理
image = transform(test)

# 选择计算设备，优先使用GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# 创建VGG16模型实例
net = vgg16()
# 加载预训练的模型权重
model = torch.load(r"D:\errorhassei\project\vggmast\DogandCat2.pth", map_location=device)
# 将加载的权重导入模型
net.load_state_dict(model)
# 将模型设置为评估模式
net.eval()

# 准备输入数据，调整为四维张量（batch_size, channels, height, width）
image = torch.reshape(image, (1, 3, 224, 224))

# 进行前向传播
with torch.no_grad():  # 指示PyTorch不需要计算梯度，节省内存和计算资源
    out = net(image)

# 应用softmax函数，将输出转换为概率分布
out = F.softmax(out, dim=1)
# 将输出数据移动到CPU，并转换为numpy数组
out = out.data.cpu().numpy()

# 打印预测结果的概率分布
print(out)

# 找到概率分布中最大值的索引，即预测的类别
a = int(out.argmax(1))

# 使用matplotlib库展示预测结果
plt.figure()
# 定义类别标签列表
list = ['Cat', 'Dog']
# 创建标题，显示预测的类别和对应的置信度
plt.suptitle(f"Classes:{list[a]:.1%}")
# 显示原图像
plt.imshow(test)
# 显示图像和标题
plt.show()
```

这段代码首先对输入的图像进行预处理，使其符合VGG16模型的输入要求。然后，加载VGG16模型和预训练权重，并设置为评估模式。接着，将处理后的图像输入模型进行前向传播，得到输出的概率分布。通过应用softmax函数，将模型的原始输出转换为概率分布。最后，代码找到概率最高的类别，并使用matplotlib库将预测结果和原图像一起展示出来。这样的脚本可以用于任何图像分类任务的预测和演示。

